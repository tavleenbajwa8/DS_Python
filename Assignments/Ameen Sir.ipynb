{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291b64db",
   "metadata": {},
   "source": [
    "Have list of names with all the items in small case and convert the items to proper noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ef1f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tavleen', 'Aaleen', 'Ravleen', 'Navleen']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [\"tavleen\", \"aaleen\", \"ravleen\", \"navleen\"]\n",
    "list(map(lambda a: a.title(), l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f6aa60",
   "metadata": {},
   "source": [
    "Get total number of reads from the user. A read is basically(a string) short sequence of nucleotide for example, 'ATTGCCTTC'. then ask user to\n",
    "give bases for each read, If user entered 10 a total get 10 sequence separtely. Show user which is the longest read and show total number of\n",
    "'A','T','G','C' across all reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9bdd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter reads: AGTAG GGG AGTACCCCCC\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'AGTAG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-858bab646f32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mccount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"A\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'AGTAG'"
     ]
    }
   ],
   "source": [
    "reads = map(int,list(map(str,input(\"Enter reads: \").upper().split())))\n",
    "longest_read = 0\n",
    "longest_seq = \"\"\n",
    "longest_ind = 0\n",
    "acount = 0\n",
    "gcount = 0\n",
    "ccount = 0\n",
    "tcount = 0\n",
    "for ind,i in enumerate(reads):\n",
    "    for j in i:\n",
    "        if j == \"A\":\n",
    "            acount+=1\n",
    "        elif j == \"G\":\n",
    "            gcount+=1\n",
    "        elif j == \"T\":\n",
    "            tcount+=1\n",
    "        elif j == \"C\":\n",
    "            ccount+=1\n",
    "        else:\n",
    "            pass\n",
    "    print(i,len(i),len(i) > longest_read)\n",
    "    if len(i) > longest_read:\n",
    "        longest_read = len(i)\n",
    "        longest_seq = i\n",
    "        longest_ind = ind\n",
    "print(\"The longest sequence is: \", reads[longest_ind])\n",
    "# for read in reads:\n",
    "#     if longest_read == len(read):\n",
    "#         print(\"Longest read(s) is: \",read)\n",
    "\n",
    "print(\"Total no. of A:\", acount, \", G:\",gcount, \", C:\",ccount, \",T:\", tcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task:\n",
    "    Download and read(parse) a CSV file and store into a dicntionary\n",
    "\n",
    "follow pseudo code Below:\n",
    "\n",
    "#step1: import pprint module\n",
    "from pprint import pprint\n",
    "\n",
    "#step2: initialise a  dicntionary with gene details\n",
    "gene_info = dict({\"name\":\"BRCA2\",\"transcripts\":[]})\n",
    "\n",
    "#step3: open the Downloaded file\n",
    "\n",
    "with open(\"path_to_file.csv\") as csv_file:\n",
    "    #step4 parse the content of the csv (line by line)\n",
    "    #step5: Append/add the data to gene_info dict\n",
    "\n",
    "\n",
    "step6: print gene_info dict\n",
    "pprint(gene_info)\n",
    "\n",
    "Example input\n",
    "\n",
    "Transcript ID, Name, protein, bp, translation ID\n",
    "ENST00000544455.1,BRCA2-201,10984,3418aa\n",
    "ENST00000380152.3,BRCA2-001,10984,3418aa\n",
    "ENST00000530893.2,BRCA2-003,10984,3418aa\n",
    "ENST00000470094.1,BRCA2-003,10984,3418aa\n",
    "ENST00000528762.1,BRCA2-003,10984,3418aa\n",
    "ENST00000533776.1,BRCA2-003,10984,3418aa\n",
    "\n",
    "outPut:\n",
    "\n",
    "{\n",
    "    \"name\":\"BRCA2\",\n",
    "    \"transcript\":[\n",
    "        {\"transcript_id\":ENST00000544455, name:BRCA2-201, protein:10984 ,bp: 3418aa  },\n",
    "        {\"transcript_id\":ENST00000380152.3, name:BRCA2-201, protein:10984 ,bp: 3418aa  },\n",
    "        {\"transcript_id\":ENST00000544455, name:BRCA2-201, protein:10984 ,bp: 3418aa  },\n",
    "        {\"transcript_id\":ENST00000530893.2, name:BRCA2-201, protein:10984 ,bp: 3418aa  },\n",
    "        {\"transcript_id\":ENST00000528762.1, name:BRCA2-201, protein:10984 ,bp: 3418aa  },\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1da653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Transcript ID', 'Name', 'bp', 'Protein', 'Translation ID', 'Biotype', 'CCDS', 'UniProt Match', 'RefSeq Match', 'Flags\\n'] <class 'list'> 10\n",
      "{'name': 'BRCA2',\n",
      " 'transcripts': [{'Transcript ID': '\"ENST00000533776.1\"'},\n",
      "                 {'Name': '\"BRCA2-205\"'},\n",
      "                 {'bp': '\"523\"'},\n",
      "                 {'Protein': '\"No protein\"'},\n",
      "                 {'Translation ID': '\"-\"'},\n",
      "                 {'Biotype': '\" Retained intron\"'},\n",
      "                 {'CCDS': '\"\"'},\n",
      "                 {'UniProt Match': '\"-\"'},\n",
      "                 {'RefSeq Match': '\"-\"'},\n",
      "                 {'Flags\\n': '\"TSL:3'}]}\n"
     ]
    }
   ],
   "source": [
    "from operator import truediv\n",
    "import pprint\n",
    "output_format = dict({\"name\":\"BRCA2\",\"transcripts\":[]})\n",
    "\n",
    "input_file = open(r\"C:\\\\Users\\\\Lakshya\\\\Downloads\\\\transcripts_ENSG00000139618.csv\")\n",
    "headers = input_file.readline()   #The readline() method returns one line from the file.\n",
    "headers = list(map(lambda headers: headers.replace('\"',''), headers.split(\",\")))\n",
    "print((headers), type(headers), len(headers)) \n",
    "\n",
    "lines = input_file.readlines()  \n",
    "#print(lines)\n",
    "\n",
    "for row in lines:\n",
    "    cols = row.split(\",\")            #The split() method splits a string into a list. You can specify the separator, default separator is any whitespace.\n",
    "    #print(cols)\n",
    "\n",
    "for col in range(len(cols)):\n",
    "    #print(col)\n",
    "    #print(cols[col])\n",
    "    try:\n",
    "        head_ = headers[col]\n",
    "        col_ = cols[col]\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        continue\n",
    "        \n",
    "    data = {}\n",
    "    data[head_] = col_\n",
    "    #print(type(data))\n",
    "    #print(type(output_format[\"transcripts\"]))\n",
    "    output_format[\"transcripts\"].append(data)\n",
    "pprint.pprint(output_format)\n",
    "   \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b277332b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-3-c1c8c5f1e9bc>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-c1c8c5f1e9bc>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    headers = list(lambda headers: headers.split(\",\")\u001b[0m\n\u001b[1;37m                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "input_file = open(r\"C:\\\\Users\\\\Lakshya\\\\Downloads\\\\transcripts_ENSG00000139618.csv\")\n",
    "headers = input_file.readline()   #The readline() method returns one line from the file.\n",
    "headers = list(lambda headers: headers.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers.replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31c591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa70ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5e8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reads = list(map(str,input(\"Enter reads: \").upper().split()))\n",
    "longest_read = 0\n",
    "acount = 0\n",
    "gcount = 0\n",
    "ccount = 0\n",
    "tcount = 0\n",
    "for i in reads:\n",
    "    for j in i:\n",
    "        if j == \"A\":\n",
    "            acount+=1\n",
    "        elif j == \"G\":\n",
    "            gcount+=1\n",
    "        elif j == \"T\":\n",
    "            tcount+=1\n",
    "        elif j == \"C\":\n",
    "            ccount+=1\n",
    "        else:\n",
    "            pass\n",
    "    if len(i) > longest_read:\n",
    "        longest_read = len(i)\n",
    "    print(\"Longest read(s) is: \", i)\n",
    "    #if longest_read == len(i):\n",
    "        #print(\"Longest read(s) is: \",read)\n",
    "\n",
    "print(\"Total no. of A:\", acount, \", G:\",gcount, \", C:\",ccount, \",T:\", tcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c426cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def csv_to_json(csv_path, json_path):\n",
    "\n",
    "    with open(csv_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        data = {\"addresses\": []}\n",
    "        for row in reader:\n",
    "             data[\"addresses\"].append({\"firstname\":\n",
    "             row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "\n",
    "csv_path = r'C:\\Users\\Lakshya\\Downloads\\addresses.csv'\n",
    "json_path = 'addresses3.json'\n",
    "csv_to_json(csv_path,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad163ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pasted pseudo-code below.\n",
    "add necessary methods for performing CSV operations. I have also made a short note under each method for understanding\n",
    "\n",
    "import json\n",
    "\n",
    "class Csvread:\n",
    "path\n",
    "data = []\n",
    "def __init__(self,path):\n",
    "\"\"\"\n",
    "Constructor\n",
    "\"\"\"\n",
    "self.path = path\n",
    "self.readfile()\n",
    "\n",
    "def save_to_json():\n",
    "json.dumps()\n",
    "\n",
    "def addItem(self,data):\n",
    "\"\"\"\n",
    "Should get dictionary from argument\n",
    "append to DAta\n",
    "\"\"\"\n",
    "self.data.append(data)\n",
    "\n",
    "def delete():\n",
    "\"\"\"\n",
    "Should delete selected Item from data\n",
    "Allow the user to selected index to delete\n",
    "\"\"\"\n",
    "\n",
    "def serach(term):\n",
    "\"\"\"\n",
    "Should be to search values of each row against the given param\n",
    "loop over the data. where each item is a dictionary. if any values of dictionary contians the quert `term`\n",
    "show as hit\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def readfile(self):\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "with open(path) as f:\n",
    "# self.data = f.read()\n",
    "for line in f:\n",
    "self.data.append(line)\n",
    "\n",
    "#example for creating object and calling methods\n",
    "csvFile = Csvread(\"path_to_file\")\n",
    "csvFile.addItem({})\n",
    "csvFile.save_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b593170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "class csvread:\n",
    "    \n",
    "    def __init__(self, csv_path, json_path, new_data):\n",
    "        self.csv_path = csv_path\n",
    "        self.json_path = json_path\n",
    "        self.new_data = new_data\n",
    "        \n",
    "        \n",
    "        \n",
    "    def save_to_json(self):\n",
    "        try:\n",
    "            with open(self.csv_path, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                next(reader)\n",
    "                data = {\"names\": []}\n",
    "                for row in reader:\n",
    "                    data[\"names\"].append({\"firstname\":\n",
    "                    row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "    def add_item(self, new_data):\n",
    "        try:\n",
    "            with open(self.new_data, 'r') as f:\n",
    "                reader = csv.DictReader(f)\n",
    "                next(reader)\n",
    "                new_data = {\"names\": []}\n",
    "                for row in reader:\n",
    "                    new_data[\"names\"].append({\"firstname\":\n",
    "                    row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "\n",
    "            with open(json_path, \"a\") as f:\n",
    "                json.dump(json_1, f, indent=4)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "csv_path = r'C:\\Users\\Lakshya\\Downloads\\addresses.csv'\n",
    "json_path = 'addresses5.json'\n",
    "json_1 = 'new_data.json'\n",
    "new_data = r'C:\\Users\\Lakshya\\Downloads\\airtravel.csv'\n",
    "d = csvread(csv_path, json_path, new_data)\n",
    "d.save_to_json()\n",
    "d.add_item(new_data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36148c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_item(self, new_data):\n",
    "    with open(self.new_data, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        next(reader)\n",
    "        new_data = {\"names\": []}\n",
    "        for row in reader:\n",
    "            new_data[\"names\"].append({\"firstname\":\n",
    "            row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "\n",
    "    with open(json_path, \"a\") as f:\n",
    "        json.dump(json_1, f, indent=4)\n",
    "\n",
    "        #except Exception as e:\n",
    "            #print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c59c836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "class csvread:\n",
    "    \n",
    "    def __init__(self, csv_path, json_path, new_data, json_1):\n",
    "        self.csv_path = csv_path\n",
    "        self.json_path = json_path\n",
    "        self.new_data = new_data\n",
    "        self.json_1 = json_1\n",
    "        \n",
    "        \n",
    "        \n",
    "    def save_to_json(self):\n",
    "        try:\n",
    "            with open(self.csv_path, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                next(reader)\n",
    "                data = {\"names\": []}\n",
    "                for row in reader:\n",
    "                    data[\"names\"].append({\"firstname\":\n",
    "                    row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "            \n",
    "    def add_item(self, new_data):\n",
    "        try:\n",
    "            with open(new_data, 'r') as fi:\n",
    "                reader = csv.DictReader(fi)\n",
    "                next(reader)\n",
    "                data1 = {\"Name\": []}\n",
    "                for row in reader:\n",
    "                    data1[\"Name\"].append({\"Name\": row[0], \"Sex\": row[1], \"Age\": row[2], \"Height\": row[3], \"Weight\": row[4]})\n",
    "\n",
    "            with open(json, \"w\") as fi:\n",
    "                json.dump(data1, f, indent=4)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "csv_path = r'C:\\Users\\Lakshya\\Downloads\\addresses.csv'\n",
    "json_path = 'addresses5.json'\n",
    "new_data = r'C:\\Users\\Lakshya\\Downloads\\biostats.csv'\n",
    "json_1 = 'new_data.json'\n",
    "d = csvread(csv_path, json_path, new_data, json_1)\n",
    "d.save_to_json()\n",
    "d.add_item(new_data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc20012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lakshya\\\\DS_Python\\\\Assignments'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9632caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "class csvread:\n",
    "    \n",
    "    def __init__(self, csv_path, json_path, new_data):\n",
    "        self.csv_path = csv_path\n",
    "        self.json_path = json_path\n",
    "        self.new_data = new_data\n",
    "        #self.json_1 = json_1\n",
    "        \n",
    "        \n",
    "        \n",
    "    def save_to_json(self):\n",
    "        with open(self.csv_path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            data = {\"names\": []}\n",
    "            for row in reader:\n",
    "                data[\"names\"].append({\"firstname\": row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "\n",
    "        with open(json_path, \"w+\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "            \n",
    "    def add_item(self):\n",
    "        with open(self.new_data, 'r') as fi:\n",
    "                reader = csv.reader(fi)\n",
    "                data1 = {\"Name\": []}\n",
    "                for row in reader:\n",
    "                    data1[\"Name\"].append({\"Name\": row[0], \"Sex\": row[1], \"Age\": row[2], \"Height\": row[3], \"Weight\": row[4]})\n",
    "                \n",
    "        with open(\"bio.json\", \"w+\") as fi:\n",
    "            json.dump(data1, fi, indent=4)\n",
    "\n",
    "    def delete(self):\n",
    "        with open(\"bio.json\", \"r+\") as del_f:\n",
    "            data = json.load(del_f)\n",
    "\n",
    "        for element in data:\n",
    "            if 'Pin' in element:\n",
    "                del element['Pin']\n",
    "\n",
    "        with open(\"bio2.json\", 'w') as data_file:\n",
    "            data = json.dump(data, data_file)\n",
    "\n",
    "csv_path = r'C:\\Users\\Lakshya\\Downloads\\addresses.csv'\n",
    "json_path = 'addresses5.json'\n",
    "new_data = r'C:\\Users\\Lakshya\\Downloads\\biostats.csv'\n",
    "#json_1 = 'new_data.json'\n",
    "d = csvread(csv_path, json_path, new_data)\n",
    "d.save_to_json()\n",
    "d.add_item()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744456f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import logging as lg\n",
    "\n",
    "lg.basicConfig(filename = \"classparser.log\", level = lg.ERROR)\n",
    "\n",
    "\n",
    "class csvread:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        def __init__(self, csv_path, json_path, new_data, json_path_2):\n",
    "            self.csv_path = csv_path\n",
    "            self.json_path = json_path\n",
    "            self.new_data = new_data\n",
    "            self.json_path_2 = json_path_2\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        self.logging(e)\n",
    "        \n",
    "        \n",
    "    \n",
    "    try: \n",
    "        \n",
    "        def save_to_json(self):\n",
    "            with open(self.csv_path, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                next(reader)\n",
    "                data = {\"names\": []}\n",
    "                for row in reader:\n",
    "                    data[\"names\"].append({\"firstname\": row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "\n",
    "                with open(json_path, \"w\") as f:\n",
    "                    json.dump(data, f, indent=4)\n",
    "\n",
    "            with open(json_path, \"w+\") as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "   \n",
    "    except Exception as e:\n",
    "        self.logging(e)\n",
    "            \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        def add_item(self):\n",
    "            with open(self.new_data, 'r') as fi:\n",
    "                    reader = csv.reader(fi)\n",
    "                    data1 = {\"Name\": []}\n",
    "                    for row in reader:\n",
    "                        data1[\"Name\"].append({\"Name\": row[0], \"Sex\": row[1], \"Age\": row[2], \"Height\": row[3], \"Weight\": row[4]})\n",
    "\n",
    "            with open(self.json_path_2, \"w+\") as fi:\n",
    "                json.dump(data1, fi, indent=4)\n",
    "\n",
    "            with open(self.json_path, 'a') as fi:\n",
    "                json.dump(data1, fi, indent=4)\n",
    "            \n",
    "    except Exception as e:\n",
    "        self.logging(e)\n",
    "        \n",
    "        \n",
    "    def logging(self, log):\n",
    "        lg.error(log)\n",
    "            \n",
    "\n",
    "\n",
    "csv_path = r'C:\\Users\\Lakshya\\Downloads\\addresses.csv'\n",
    "json_path = 'addresses5.json'\n",
    "new_data = r'C:\\Users\\Lakshya\\Downloads\\biostats.csv'\n",
    "json_path_2 = \"bio.json\"\n",
    "d = csvread(csv_path, json_path, new_data, json_path_2)\n",
    "d.save_to_json()\n",
    "d.add_item()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34462efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': [{'Name': 'Name', 'Sex': '     \"Sex\"', 'Age': ' \"Age\"', 'Height': ' \"Height\"', 'Weight': ' \"Weight\"'}, {'Name': 'Alex', 'Sex': '       \"M\"', 'Age': '41', 'Height': '74', 'Weight': '170'}, {'Name': 'Bert', 'Sex': '       \"M\"', 'Age': '42', 'Height': '68', 'Weight': '166'}, {'Name': 'Carl', 'Sex': '       \"M\"', 'Age': '32', 'Height': '70', 'Weight': '155'}, {'Name': 'Dave', 'Sex': '       \"M\"', 'Age': '39', 'Height': '72', 'Weight': '167'}, {'Name': 'Elly', 'Sex': '       \"F\"', 'Age': '30', 'Height': '66', 'Weight': '124'}, {'Name': 'Fran', 'Sex': '       \"F\"', 'Age': '33', 'Height': '66', 'Weight': '115'}, {'Name': 'Gwen', 'Sex': '       \"F\"', 'Age': '26', 'Height': '64', 'Weight': '121'}, {'Name': 'Hank', 'Sex': '       \"M\"', 'Age': '30', 'Height': '71', 'Weight': '158'}, {'Name': 'Ivan', 'Sex': '       \"M\"', 'Age': '53', 'Height': '72', 'Weight': '175'}, {'Name': 'Jake', 'Sex': '       \"M\"', 'Age': '32', 'Height': '69', 'Weight': '143'}, {'Name': 'Kate', 'Sex': '       \"F\"', 'Age': '47', 'Height': '69', 'Weight': '139'}, {'Name': 'Luke', 'Sex': '       \"M\"', 'Age': '34', 'Height': '72', 'Weight': '163'}, {'Name': 'Myra', 'Sex': '       \"F\"', 'Age': '23', 'Height': '62', 'Weight': '98'}, {'Name': 'Neil', 'Sex': '       \"M\"', 'Age': '36', 'Height': '75', 'Weight': '160'}, {'Name': 'Omar', 'Sex': '       \"M\"', 'Age': '38', 'Height': '70', 'Weight': '145'}, {'Name': 'Page', 'Sex': '       \"F\"', 'Age': '31', 'Height': '67', 'Weight': '135'}, {'Name': 'Quin', 'Sex': '       \"M\"', 'Age': '29', 'Height': '71', 'Weight': '176'}, {'Name': 'Ruth', 'Sex': '       \"F\"', 'Age': '28', 'Height': '65', 'Weight': '131'}]}\n",
      "\n",
      "Name\n"
     ]
    }
   ],
   "source": [
    "with open(\"bio.json\") as data_file:\n",
    "    data = json.load(data_file)\n",
    "    headers = data_file.readline()\n",
    "    print(data)\n",
    "    print(headers)\n",
    "\n",
    "for element in data:\n",
    "    print(element)\n",
    "    \n",
    "    \n",
    "    #headers = input_file.readline()\n",
    "#headers = list(map(lambda headers: headers.replace('\"',''), headers.split(\",\")))\n",
    "#print((headers), type(headers), len(headers)) \n",
    "\n",
    "    #if '2-uID' in element:\n",
    "        #del element['2-uID']\n",
    "\n",
    "#with open(\"path/to/json\", 'w') as data_file:\n",
    "    #data = json.dump(data, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924aa9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776687e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62842623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import logging as lg\n",
    "\n",
    "lg.basicConfig(filename = \"classparser.log\", level = lg.ERROR)\n",
    "\n",
    "\n",
    "class csvread:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        def __init__(self, csv_path, json_path, new_data, json_path_2):\n",
    "            self.csv_path = csv_path\n",
    "            self.json_path = json_path\n",
    "            self.new_data = new_data\n",
    "            self.json_path_2 = json_path_2\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        self.logging(e)\n",
    "        \n",
    "        \n",
    "    \n",
    "    try: \n",
    "        \n",
    "        def save_to_json(self):\n",
    "            with open(self.csv_path, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                next(reader)\n",
    "                data = {\"names\": []}\n",
    "                for row in reader:\n",
    "                    data[\"names\"].append({\"firstname\": row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "\n",
    "                with open(json_path, \"w\") as f:\n",
    "                    json.dump(data, f, indent=4)\n",
    "\n",
    "            with open(json_path, \"w+\") as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "   \n",
    "    except Exception as e:\n",
    "        self.logging(e)\n",
    "            \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        def add_item(self):\n",
    "            with open(self.new_data, 'r') as fi:\n",
    "                    reader = csv.reader(fi)\n",
    "                    data1 = {\"Name\": []}\n",
    "                    for row in reader:\n",
    "                        data1[\"Name\"].append({\"Name\": row[0], \"Sex\": row[1], \"Age\": row[2], \"Height\": row[3], \"Weight\": row[4]})\n",
    "\n",
    "            with open(self.json_path_2, \"w+\") as fi:\n",
    "                json.dump(data1, fi, indent=4)\n",
    "\n",
    "            with open(self.json_path, 'a') as fi:\n",
    "                json.dump(data1, fi, indent=4)\n",
    "            \n",
    "    except Exception as e:\n",
    "        self.logging(e)\n",
    "        \n",
    "        \n",
    "    def logging(self, log):\n",
    "        lg.error(log)\n",
    "            \n",
    "\n",
    "\n",
    "csv_path = r'C:\\Users\\Lakshya\\Downloads\\addresses.csv'\n",
    "json_path = 'addresses5.json'\n",
    "new_data = r'C:\\Users\\Lakshya\\Downloads\\biostats.csv'\n",
    "json_path_2 = \"bio.json\"\n",
    "d = csvread(csv_path, json_path, new_data, json_path_2)\n",
    "d.save_to_json()\n",
    "d.add_item()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2045d6c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f813d7d989c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0md1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCsvread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0md1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-f813d7d989c8>\u001b[0m in \u001b[0;36madd_item\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mdata1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"bio\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                     data[\"bio\"].append({\"firstname\":\n\u001b[0m\u001b[0;32m     18\u001b[0m                     row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'bio'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "class Csvread:\n",
    "    \n",
    "    def __init__(self,new_data, json_1):\n",
    "        \n",
    "        self.new_data = new_data\n",
    "        self.json_1 = json_1\n",
    "        \n",
    "    def add_item(self):\n",
    "        with open(self.new_data, 'r') as fi:\n",
    "                data = {}\n",
    "                reader = csveader(fi)\n",
    "                data1 = {\"Na\": []}\n",
    "                for row in reader:\n",
    "                    data[\"names\"].append({\"firstname\":\n",
    "                    row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "                \n",
    "                print(data)\n",
    "            \n",
    "            \n",
    "\n",
    "new_data = r'C:\\Users\\Lakshya\\Downloads\\biostats.csv'\n",
    "json_1 = 'new_data.json'\n",
    "d1 = Csvread(new_data, json_1)\n",
    "\n",
    "d1.add_item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a882220a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    with open(json_1, \"w\") as fi:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "data = {\"names\": []}\n",
    "                for row in reader:\n",
    "                    data[\"names\"].append({\"firstname\":\n",
    "                    row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "        with open(json_1, \"w\") as fi:\n",
    "            json.dump(data1, fi, indent=4)   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5a76c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(r'C:\\Users\\Lakshya\\Downloads\\biostats.csv', 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            data = {\"Name\": []}\n",
    "            for row in reader:\n",
    "                data[\"Name\"].append({\"Name\":\n",
    "                row[0], \"Sex\": row[1], \"Age\": row[2], \"Height\": row[3], \"Weight\": row[4]})\n",
    "\n",
    "with open('addresses8.json', \"w+\") as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3713ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "class csvread:\n",
    "    \n",
    "    def __init__(self, csv_path, json_path, new_data, json_1):\n",
    "        self.csv_path = csv_path\n",
    "        self.json_path = json_path\n",
    "        self.new_data = new_data\n",
    "        self.json_1 = json_1\n",
    "        \n",
    "        \n",
    "        \n",
    "    def save_to_json(self):\n",
    "        with open(self.csv_path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            data = {\"names\": []}\n",
    "            for row in reader:\n",
    "                data[\"names\"].append({\"firstname\": row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "\n",
    "        with open(json_path, \"w+\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "            \n",
    "    def add_item(self):\n",
    "        with open(self.new_data, 'r') as fi:\n",
    "                reader = csv.reader(fi)\n",
    "                data1 = {\"Name\": []}\n",
    "                for row in reader:\n",
    "                    data1[\"Name\"].append({\"Name\": row[0], \"Sex\": row[1], \"Age\": row[2], \"Height\": row[3], \"Weight\": row[4]})\n",
    "                \n",
    "        with open(\"bio.json\", \"w+\") as fi:\n",
    "            json.dump(data1, fi, indent=4)\n",
    "            \n",
    "        with open(self.json_path, 'a') as fi:\n",
    "            json.dump(data1, fi, indent=4)\n",
    "            \n",
    "    \n",
    "            \n",
    "\n",
    "\n",
    "csv_path = r'C:\\Users\\Lakshya\\Downloads\\addresses.csv'\n",
    "json_path = 'addresses5.json'\n",
    "new_data = r'C:\\Users\\Lakshya\\Downloads\\biostats.csv'\n",
    "d = csvread(csv_path, json_path, new_data, json_1)\n",
    "d.save_to_json()\n",
    "d.add_item()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5daa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import logging as lg\n",
    "\n",
    "lg.basicConfig(filename = \"classparser.log\", level = lg.ERROR)\n",
    "\n",
    "\n",
    "class csvread:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        def __init__(self, csv_path, json_path, new_data, json_path_2):\n",
    "            self.csv_path = csv_path\n",
    "            self.json_path = json_path\n",
    "            self.new_data = new_data\n",
    "            self.json_path_2 = json_path_2\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        self.logging(e)\n",
    "        \n",
    "        \n",
    "    \n",
    "    try: \n",
    "        \n",
    "        def save_to_json(self):\n",
    "            with open(self.csv_path, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                next(reader)\n",
    "                data = {\"names\": []}\n",
    "                for row in reader:\n",
    "                    data[\"names\"].append({\"firstname\": row[0], \"lastname\": row[1], \"Building\": row[2], \"Town\": row[3], \"City\": row[4], \"Pin\": row[5]})\n",
    "\n",
    "                with open(json_path, \"w\") as f:\n",
    "                    json.dump(data, f, indent=4)\n",
    "\n",
    "            with open(json_path, \"w+\") as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "   \n",
    "    except Exception as e:\n",
    "        self.logging(e)\n",
    "            \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        def add_item(self):\n",
    "            with open(self.new_data, 'r') as fi:\n",
    "                    reader = csv.reader(fi)\n",
    "                    data1 = {\"Name\": []}\n",
    "                    for row in reader:\n",
    "                        data1[\"Name\"].append({\"Name\": row[0], \"Sex\": row[1], \"Age\": row[2], \"Height\": row[3], \"Weight\": row[4]})\n",
    "\n",
    "            with open(self.json_path_2, \"w+\") as fi:\n",
    "                json.dump(data1, fi, indent=4)\n",
    "\n",
    "            with open(self.json_path, 'a') as fi:\n",
    "                json.dump(data1, fi, indent=4)\n",
    "            \n",
    "    except Exception as e:\n",
    "        self.logging(e)\n",
    "        \n",
    "        \n",
    "    def logging(self, log):\n",
    "        lg.error(log)\n",
    "            \n",
    "\n",
    "\n",
    "csv_path = r'C:\\Users\\Lakshya\\Downloads\\addresses.csv'\n",
    "json_path = 'addresses5.json'\n",
    "new_data = r'C:\\Users\\Lakshya\\Downloads\\biostats.csv'\n",
    "json_path_2 = \"bio.json\"\n",
    "d = csvread(csv_path, json_path, new_data, json_path_2)\n",
    "d.save_to_json()\n",
    "d.add_item()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0df268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
